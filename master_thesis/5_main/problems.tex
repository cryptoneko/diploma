\section{Задача}

Позначимо множину $T$ зображень.
Кольори --- відтінки сірого, що визначаються лише інтенсивністю від $0$ до $1$.
Введемо множину $I$ пікселів зображення.
Зображення $t \in T$ є відображення з множини пікселів на множину їх значень
\begin{equation*}
  t: I \rightarrow \left[ 0; 1 \right].
\end{equation*}
Інтенсивність пікселя $i$ в зображенні $t$ позначимо як $t_i$.

Взагалі кажучи, $I$ --- множина індексів матриць однакового розміру
\begin{equation*}
  I = \left\{ \left\langle i, j \right\rangle
    \;\middle|\; i = 1..h,\; j = 1..w \right\}.
\end{equation*}
Зазвичай використовуються зображення розміром від
$100 \times 100 = 10^4$ пікселів.
Проте сучасні камери на фотоапаратах, смартфонах та інших пристроях
можуть зробити зображення площиною кілька мільйонів пікселів і більше.
При використанні $2^8 = 256$ градацій сірого маємо
$10^{6 \cdot 256} = 10^{1536}$ різних зображень розміром $1000 \times 1000$,
тобто неймовірно багато.

Тривимірна модель обличчя визначається набором $n$ дійсних параметрів.
Множина всіх параметрів $X = \mathbb{R}^n$.
Функцією, що перетворює набір параметрів на зображення, є відображення
\begin{equation*}
  f: X \rightarrow T.
\end{equation*}
Введемо позначення для зображення згенерованого з певним набором параметрів $x$
\begin{equation*}
  f\left( x \right) = t.
\end{equation*}
Інтенсивність $i$ пікселя позначимо
\begin{equation*}
  f_i\left( x \right) = t_i.
\end{equation*}

Поставимо Баєсову задачу розпізнавання.
Для цього потрібно визначитися з функцією витрат
\cite{berger1980}
\begin{equation*}
  W: X \times X \rightarrow \mathbb{R}.
\end{equation*}
Введемо множину стратегій розпізнавання $Q$ як функцій,
які кожному $t \in T$ ставлять у відповідність параметри,
з якими було згенеровано обличчя на даному зображенні
\begin{equation*}
  Q = X^T.
\end{equation*}
Стратегію $q \in Q$, яка для зображення $t$ дає результат $x$, позначимо
\begin{equation*}
  q\left( t \right) = x.
\end{equation*}
Математичне очікування функції витрат для даного вирішального правила $q$
як функції випадкової величини $x$ за умови,
що було пред'явлено зображення $t$, називається Баєсовим ризиком
\cite{schlesinger:2002}
\begin{equation*}
  R \left( q \right)
  = \sum\limits_{t \in T} \sum\limits_{x \in X}
    \mathbb{P}\left( x,  q\left( t \right) \right)
    \cdot W \left( x, q\left( t \right) \right).
\end{equation*}
Задача --- знайти таке вирішальне правило $q$, яке мінімізує Баєсів ризик
\begin{equation*}
  q^* = \argmin_{q \in Q} R.
\end{equation*}

\subsection{Бінарна функція витрат}

Досить росповсюдженою, проте зазвичай неприродною є бінарна функція штрафу
\begin{equation*}
  W \left( x, x' \right)
  = \mathbbm{1} \left( x \neq x' \right).
\end{equation*}

Оберемо стратегію $q^*$,
що мінімізує математичне очікування цієї функції витрат
\begin{equation*}
  \begin{split}
    q^* \left( t \right)
    = \argmin_{x'} \left\{
      \sum\limits_{x \in X}
        \mathbb{P}\left( x \;\middle|\;  t \right)
        \cdot \mathbbm{1} \left( x \neq x' \right)
      \right\} = \\
    = \argmin_{x'} \left\{
      \sum\limits_{x \in X}
        \mathbb{P}\left( x \;\middle|\;  t \right)
      - \sum\limits_{x \in X}
        \mathbb{P}\left( x \;\middle|\;  t \right)
        \cdot \mathbbm{1} \left( x = x' \right)
      \right\} = \\
    = \argmin_{x'} \left\{
      1 - \mathbb{P}\left( x' \;\middle|\;  t \right)
      \right\}.
  \end{split}
\end{equation*}
В результаті
\begin{equation*}
  q^* \left( t \right)
  = \argmax_x \mathbb{P} \left( x \;\middle|\;  t \right).
\end{equation*}

Отже, якщо використовується бінарна функція витрат,
потрібно обирати найбільш ймовірний варіант.
Така задача може бути розумною, коли є небагато різних варіантів відповіді.
Проте в даному випадку відповідь --- набір з сотень дійсних чисел.
Аналітичного виразу для розрахування $f$ немає,
отже доведеться скористатися чисельними методами,
які не дадуть точної відповіді.

Очевидно,
що для неперервного випадку така функція зовсім не підходить.
Тому що інтеграл
\begin{equation*}
  \int\limits_{x \in X} \mathbbm{1} \left( x \neq x' \right)
  \cdot p\left( x \;\middle|\;  t \right) d\, x = 1.
\end{equation*}
Тобто майже ніде немає вірної відповіді, бо майже всюди сплачується штраф.

\subsection{Різниця моделей}

Розглянемо більш природню функцію витрат ---
квадрат евклідової відстані між точками дійсної та обраної моделі.

Введемо множину вершин обличчя $V$.
Кожна вершина має певні координати в тривимірному просторі $\mathbb{R}^3$.
Модель обличчя --- відображення,
яке кожній вершині $v$ ставить у відповідність її координати
\begin{equation*}
  M: V \rightarrow \mathbb{R}^3.
\end{equation*}
Породжувальна модель обличчя --- відображення,
яке кожному набору параметрів $x$ ставить у відповідність модель $m$
\begin{equation*}
  G: X \rightarrow M.
\end{equation*}
Координати $g$ вершини $v$ моделі згенерованої з параметрами $x$ позначимо
\begin{equation*}
  G_v\left( x \right) = g.
\end{equation*}

Координати кожної вершини $v$ породжувальної моделі отримуються шляхом
перемноження компонент параметру $x$ на відповідний коефіцієнт $\lambda^v$
отриманий за допомогою методу головних компонент
та додавання результату до середнього положення поточної вершини
\begin{equation*}
  G_v\left( x \right) = g_0^v + \sum_{i \in 1}^n \lambda_i^v \cdot x_i,
  \qquad v \in V.
\end{equation*}

Функція витрат має вигляд
\begin{equation*}
  \begin{split}
    W \left( x, x' \right)
    = \left\| G\left( x \right) - G\left( x' \right) \right\|^2
    = \sum_{v \in V} \left[
        G_v\left( x \right) - G_v\left( x' \right)
      \right]^2 = \\
    = \sum_{v \in V} \sum_{p \in P} \left[
        \lambda_p^v \cdot \left( x_p - x'_p \right)
      \right]^2
    = \sum_{p \in P} \left\{ \left( x_p - x'_p \right)^2
      \cdot \sum_{v \in V} \left( \lambda_p^v \right)^2 \right\} = \\
    = \left| \beta_p^2 = \sum_{v \in V} \left( \lambda_p^v \right)^2 \right|
    = \sum_{p \in P} \beta_p^2 \cdot \left( x_p - x'_p \right)^2.
  \end{split}
\end{equation*}

Оберемо стратегію $q^*$,
що мінімізує математичне очікування цієї функції витрат
\begin{equation*}
  q^* \left( t \right)
  = \argmin_{x'} \left\{
    \sum\limits_{x \in X} \left[
        \mathbb{P} \left( x \;\middle|\;  t \right)
        \cdot \sum_{i = 1}^n \beta_i^2 \cdot \left( x'_i - x_i \right)^2
      \right]
    \right\}.
\end{equation*}
Щоб мінімізувати неперервну функцію від параметрів $x'_i$,
можна взяти по них похідну
\begin{equation*}
  \frac{\partial \sum\limits_{x \in X} \left[
      \mathbb{P} \left( x \;\middle|\;  t \right)
      \cdot \sum\limits_{i = 1}^n \beta_i^2 \cdot \left( x'_i - x_i \right)^2
  \right]}{\partial x'_i}
  = 2 \cdot \sum_{x \in X} \mathbb{P} \left( x \;\middle|\;  t \right)
    \cdot \beta_i^2 \cdot \left( x'_i - x_i \right), \qquad i = 1..n
\end{equation*}
та прирівняти до нуля
\begin{equation*}
  \sum_{x \in X} \mathbb{P} \left( x \;\middle|\;  t \right)
  \cdot \left( x'_i - x_i \right) = 0, \qquad i = 1..n.
\end{equation*}
Значення компоненти
\begin{equation*}
  x'_i = \frac{\sum\limits_{x \in X}
    \mathbb{P} \left( x \;\middle|\;  t \right) \cdot x_i}
    {\sum\limits_{x \in X}
      \mathbb{P} \left( x \;\middle|\;  t \right)}
  = \sum\limits_{x \in X}
    \mathbb{P} \left( x \;\middle|\;  t \right) \cdot x_i, \qquad i = 1..n.
\end{equation*}
Результуюча стратегія
\begin{equation*}
  q^*\left( t \right)
  = \sum_{x \in X} x \cdot \mathbb{P}\left( x \mid t \right).
\end{equation*}
У випадку неперервного розподілу ймовірностей
\begin{equation*}
  q^*\left( t \right)
  = \int\limits_{x \in X} x \cdot p\left( x \mid t \right) d\,x.
\end{equation*}

\subsection{Різниця параметрів}

Розглянемо більш просту функцію витрат ---
квадрат евклідової норми різниці між дійсними та обраними параметрами
моделі зображеного обличчя
\begin{equation*}
  W \left( x, x' \right)
  = \left\| x - x' \right\|^2
  = \sum_{p \in P} \left( x_p - x'_p \right)^2.
\end{equation*}

Оберемо стратегію $q^*$,
що мінімізує математичне очікування цієї функції витрат
\begin{equation*}
  q^* \left( t \right)
  = \argmin_{x'} \left\{
    \sum\limits_{x \in X} \left[
        \mathbb{P} \left( x \;\middle|\;  t \right)
        \cdot \sum_{i = 1}^n \left( x'_i - x_i \right)^2
      \right]
    \right\}.
\end{equation*}
Маємо мінімізацію неперервної функції від параметрів $x'_i$,
отже можемо взяти по них похідну
\begin{equation*}
  \frac{\partial \sum\limits_{x \in X} \left[
      \mathbb{P} \left( x \;\middle|\;  t \right)
      \cdot \sum\limits_{i = 1}^n \left( x'_i - x_i \right)^2
  \right]}{\partial x'_i}
  = 2 \cdot \sum_{x \in X} \mathbb{P} \left( x \;\middle|\;  t \right)
    \cdot \left( x'_i - x_i \right), \qquad i = 1..n
\end{equation*}
та прирівняти до нуля
\begin{equation*}
  \sum_{x \in X} \mathbb{P} \left( x \;\middle|\;  t \right)
  \cdot \left( x'_i - x_i \right) = 0, \qquad i = 1..n.
\end{equation*}
Значення компоненти
\begin{equation*}
  x'_i = \frac{\sum\limits_{x \in X}
    \mathbb{P} \left( x \;\middle|\;  t \right) \cdot x_i}
    {\sum\limits_{x \in X}
      \mathbb{P} \left( x \;\middle|\;  t \right)}
  = \sum\limits_{x \in X}
    \mathbb{P} \left( x \;\middle|\;  t \right) \cdot x_i, \qquad i = 1..n.
\end{equation*}
Результуюча стратегія
\begin{equation*}
  q^*\left( t \right)
  = \sum_{x \in X} x \cdot \mathbb{P}\left( x \mid t \right).
\end{equation*}
У випадку неперервного розподілу ймовірностей
\begin{equation*}
  q^*\left( t \right)
  = \int\limits_{x \in X} x \cdot p\left( x \mid t \right) d\,x.
\end{equation*}

Отримана та ж стратегія,
що мінімізує математичне очікування суми квадратів різниць
координат вершин дійсної та обраної моделі обличчя.
Тобто це вирішувальне правило розв'язує обидві задачі.
